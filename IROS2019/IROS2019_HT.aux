\relax 
\citation{dissanayake2001solution}
\citation{peneda2009trilateration,jung2011indoor}
\citation{peneda2009trilateration,jung2011indoor,raghavan2010accurate}
\citation{newman2003pure,olson2006robust}
\citation{fabresse2018efficient}
\citation{li2017novel}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}}
\citation{li2017novel}
\citation{caballero2008particle}
\citation{lecun2015deep}
\citation{elman1990finding}
\citation{walch2017image,gladh2016deep,wang2017deepvo,kendall2015posenet,turan2018deep}
\citation{rahman2009localization,singh2013tdoa,abdelhadi2013efficient,kumar2016localization,banihashemian2018new}
\citation{lim2018effective}
\citation{lecun2015deep}
\citation{hochreiter1997long}
\citation{cho2014learning}
\citation{schuster1997bidirectional}
\citation{thomas2005revisiting,cho2010mobile,raghavan2010accurate}
\citation{blanco2008pure,blanco2008efficient,fabresse2013undelayed,shetty2018particle}
\citation{tran2008localization,huan2010three,feng2012determination,afzal2014localization}
\citation{lee2013new,lee2013novel}
\citation{tran2008localization}
\citation{chatterjee2010fletcher,feng2012determination,afzal2014localization}
\citation{samadian2011probabilistic}
\citation{lee2013new,lee2013novel}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example}{{\caption@xref {fig:example}{ on input line 150}}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces System overview. A robot localizes its own pose through distance data and the derivative of distance data. \relax }}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Works}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Conventional RO SLAM}{2}}
\citation{chenna2004state}
\citation{shareef2008localization}
\citation{shareef2008localization}
\citation{rahman2009localization}
\citation{singh2013tdoa}
\citation{abdelhadi2013efficient}
\citation{bernas2015fully}
\citation{kumar2016localization}
\citation{banihashemian2018new}
\citation{shareef2008localization,rahman2009localization,singh2013tdoa,abdelhadi2013efficient,bernas2015fully,kumar2016localization,banihashemian2018new}
\citation{rahman2009localization}
\citation{singh2013tdoa}
\citation{abdelhadi2013efficient}
\citation{kumar2016localization}
\citation{banihashemian2018new}
\citation{chatterjee2010fletcher,shareef2008localization,rahman2009localization,singh2013tdoa,banihashemian2018new}
\citation{rahman2009localization}
\citation{shareef2008localization,rahman2009localization,singh2013tdoa,bernas2015fully,kumar2016localization,banihashemian2018new}
\citation{shareef2008localization,rahman2009localization,singh2013tdoa,kumar2016localization}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}Neural Networks-based Localization}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}RO SLAM with Neural Networks}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}WSN Net}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}long short-Term Memory}{3}}
\citation{schuster1997bidirectional}
\citation{zhang2017multi,li2018human,ullah2018action}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Comparison of previous studies with our approach\relax }}{4}}
\newlabel{table:related_worsk}{{I}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Our proposed network architecture.\relax }}{4}}
\newlabel{fig:our_network}{{2}{4}}
\newlabel{eq:forget}{{1}{4}}
\newlabel{eq:input}{{2}{4}}
\newlabel{eq:new_cell}{{3}{4}}
\newlabel{eq:update}{{4}{4}}
\newlabel{eq:output}{{5}{4}}
\newlabel{eq:hidden}{{6}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Bidirectional LSTM}{4}}
\citation{fabresse2013undelayed}
\citation{simonyan2014very,he2016deep}
\citation{graves2013hybrid,graves2013speech,ullah2018action}
\citation{pascanu2013difficulty}
\citation{nair2010rectified}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of the LSTM. It consists of 3 gates, forget gate(the part inside the red box), input gate(the part inside the blue box), and output gate. And output gate is divided into cell state layer(the part inside the green box) and output gate layer(the part inside the cyan box) \relax }}{5}}
\newlabel{fig:basic_lstm}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Architecture of the Bidirectional LSTM(Bi-LSTM)\relax }}{5}}
\newlabel{fig:bidirectional_revised}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Stacked Architecture}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Training loss}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Experimental environment}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The anchor and tag nodes\relax }}{6}}
\newlabel{fig:anchor_tag_nodes}{{5}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Four example of the trajectories\relax }}{6}}
\newlabel{fig:paths}{{6}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Data syncronization for Train/Test data}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces the process that makes dataset\relax }}{7}}
\newlabel{fig:dataset}{{7}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Training the Networks}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-A}Performance according to the sequence length}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Error bar graph of RMSE with respect to sequence length\relax }}{7}}
\newlabel{fig:seq_length}{{8}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Root mean squared error of each case\relax }}{7}}
\newlabel{table:RMSE_sequence}{{II}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-B}Performance comparison result}{7}}
\bibstyle{IEEEtran}
\bibdata{./IEEEabrv,./IROS_RObib}
\bibcite{dissanayake2001solution}{1}
\bibcite{peneda2009trilateration}{2}
\bibcite{jung2011indoor}{3}
\bibcite{raghavan2010accurate}{4}
\bibcite{newman2003pure}{5}
\bibcite{olson2006robust}{6}
\bibcite{fabresse2018efficient}{7}
\bibcite{li2017novel}{8}
\bibcite{caballero2008particle}{9}
\bibcite{lecun2015deep}{10}
\bibcite{elman1990finding}{11}
\bibcite{walch2017image}{12}
\bibcite{gladh2016deep}{13}
\bibcite{wang2017deepvo}{14}
\bibcite{kendall2015posenet}{15}
\bibcite{turan2018deep}{16}
\bibcite{rahman2009localization}{17}
\bibcite{singh2013tdoa}{18}
\bibcite{abdelhadi2013efficient}{19}
\bibcite{kumar2016localization}{20}
\bibcite{banihashemian2018new}{21}
\bibcite{lim2018effective}{22}
\bibcite{hochreiter1997long}{23}
\bibcite{cho2014learning}{24}
\bibcite{schuster1997bidirectional}{25}
\bibcite{thomas2005revisiting}{26}
\bibcite{cho2010mobile}{27}
\bibcite{blanco2008pure}{28}
\bibcite{blanco2008efficient}{29}
\bibcite{fabresse2013undelayed}{30}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{8}}
\@writefile{toc}{\contentsline {section}{References}{8}}
\bibcite{shetty2018particle}{31}
\bibcite{tran2008localization}{32}
\bibcite{huan2010three}{33}
\bibcite{feng2012determination}{34}
\bibcite{afzal2014localization}{35}
\bibcite{lee2013new}{36}
\bibcite{lee2013novel}{37}
\bibcite{chatterjee2010fletcher}{38}
\bibcite{samadian2011probabilistic}{39}
\bibcite{chenna2004state}{40}
\bibcite{shareef2008localization}{41}
\bibcite{bernas2015fully}{42}
\bibcite{zhang2017multi}{43}
\bibcite{li2018human}{44}
\bibcite{ullah2018action}{45}
\bibcite{simonyan2014very}{46}
\bibcite{he2016deep}{47}
\bibcite{graves2013hybrid}{48}
\bibcite{graves2013speech}{49}
\bibcite{pascanu2013difficulty}{50}
\bibcite{nair2010rectified}{51}
