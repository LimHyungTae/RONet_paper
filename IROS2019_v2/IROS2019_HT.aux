\relax 
\citation{jung2015magnetic,medina2013ultrasound,li2014lidar}
\citation{peneda2009trilateration,jung2011indoor}
\citation{newman2003pure,olson2006robust}
\citation{li2017novel}
\citation{fabresse2018efficient}
\citation{gonzalez2009mobile}
\citation{rahman2009localization,abdelhadi2013efficient,kumar2016localization,lim2018effective}
\citation{rahman2009localization,abdelhadi2013efficient,kumar2016localization}
\citation{lim2018effective}
\citation{rahman2009localization,abdelhadi2013efficient,kumar2016localization}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:overview}{{\caption@xref {fig:overview}{ on input line 94}}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison between a conventional probabilistic-based range-only frameworks and our learning-based approach.\relax }}{1}}
\citation{gonzalez2009mobile,blanco2008pure,shetty2018particle}
\citation{lecun2015deep}
\citation{kendall2016modelling,kendall2015posenet,gladh2016deep}
\citation{elman1990finding}
\citation{hochreiter1997long}
\citation{clark2017vinet,patel2018contextualnet,wang2017deepvo}
\citation{wang2018deepml}
\citation{chen2018ionet}
\citation{rahman2009localization,abdelhadi2013efficient,kumar2016localization}
\citation{lim2018effective}
\citation{wang2017residual}
\citation{luong2015effective}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Works}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Conventional Range-Only Localization}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}LSTM-based Sequential Modeling}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}Deep Learning for Range Only Localization}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-D}Attention Layer}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}RONet}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Long Short-Term Memory}{2}}
\citation{simonyan2014very,he2016deep}
\citation{graves2013hybrid,graves2013speech,ullah2018action}
\citation{schuster1997bidirectional}
\citation{hochreiter2001gradient,pascanu2013difficulty,pascanu2012understanding}
\citation{nair2010rectified}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Our networks consist of three elements: a) Bi--LSTM, b) the residual attention module (the blue cuboid), and c) the fully connected layer (FC layer). Features are input to the Bi--LSTM, which reduces the number of features in half from 2048 to 1024 to 512. Finally, extracted features are input to the FC layer to estimate the position corresponding to each time step.\relax }}{3}}
\newlabel{fig:our_network}{{2}{3}}
\newlabel{eq:forget}{{1}{3}}
\newlabel{eq:input}{{2}{3}}
\newlabel{eq:new_cell}{{3}{3}}
\newlabel{eq:update}{{4}{3}}
\newlabel{eq:output}{{5}{3}}
\newlabel{eq:hidden}{{6}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Stacked Bidirectional LSTM}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of the bidirectional LSTM (Bi--LSTM). The bidirectional LSTM consists of two LSTMs: one forward (right arrow) and one backward (left arrow) LSTM layer.\relax }}{3}}
\newlabel{fig:bidirectional_revised}{{3}{3}}
\citation{wang2017residual}
\citation{he2016deep}
\citation{xavier2018}
\citation{turtlebot22013}
\citation{pozyx2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Residual Attention Layer}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Training Loss}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental Results and Discussion}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Experimental Environment}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Acquisition of the Train/Test Data}{4}}
\citation{gonzalez2009mobile}
\citation{kumar2016localization}
\citation{lim2018effective}
\citation{kumar2016localization}
\citation{lim2018effective}
\citation{gonzalez2009mobile,blanco2008pure}
\citation{gonzalez2009mobile}
\newlabel{fig:whole_system}{{4a}{5}}
\newlabel{sub@fig:whole_system}{{a}{5}}
\newlabel{fig:Optitrack_figure}{{4b}{5}}
\newlabel{sub@fig:Optitrack_figure}{{b}{5}}
\newlabel{fig:Exact_position}{{4c}{5}}
\newlabel{sub@fig:Exact_position}{{c}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces (a) Experimental environment. (b) Tracked pose from Optitrack motion capture. (c) Exact position of anchor nodes. \relax }}{5}}
\newlabel{fig:experimental_envorinment}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Training the Network}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-D}Localization Results}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {IV-D.1}Performance according to the sequence length}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Plot of root-mean-square error (RMSE) with respect to (w.r.t.) the sequence length for various numbers of anchors.\relax }}{5}}
\newlabel{fig:seq_length_on_different_anchors}{{5}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {IV-D.2}Performance comparison of other algorithms}{5}}
\bibstyle{IEEEtran}
\bibdata{./IROS_RObib,./IEEEabrv}
\bibcite{jung2015magnetic}{1}
\bibcite{medina2013ultrasound}{2}
\bibcite{li2014lidar}{3}
\newlabel{fig:anchor_3}{{6a}{6}}
\newlabel{sub@fig:anchor_3}{{a}{6}}
\newlabel{fig:anchor_5}{{6b}{6}}
\newlabel{sub@fig:anchor_5}{{b}{6}}
\newlabel{fig:anchor_8}{{6c}{6}}
\newlabel{sub@fig:anchor_8}{{c}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Trajectories corresponding to various numbers of anchors: (a) three anchors, (b) five anchors, and (c) eight anchors. For clarity, only the PF-based (orange) and our RONet results (blue) are presented.\relax }}{6}}
\newlabel{fig:trajectories_358}{{6}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Root Mean Square Error of each algorithm w.r.t. the number of anchors\relax }}{6}}
\newlabel{table:rmse}{{I}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Box plot results w.r.t. the number of anchors.\relax }}{6}}
\newlabel{fig:box_plot}{{7}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{6}}
\@writefile{toc}{\contentsline {section}{References}{6}}
\bibcite{peneda2009trilateration}{4}
\bibcite{jung2011indoor}{5}
\bibcite{newman2003pure}{6}
\bibcite{olson2006robust}{7}
\bibcite{li2017novel}{8}
\bibcite{fabresse2018efficient}{9}
\bibcite{gonzalez2009mobile}{10}
\bibcite{rahman2009localization}{11}
\bibcite{abdelhadi2013efficient}{12}
\bibcite{kumar2016localization}{13}
\bibcite{lim2018effective}{14}
\bibcite{blanco2008pure}{15}
\bibcite{shetty2018particle}{16}
\bibcite{lecun2015deep}{17}
\bibcite{kendall2016modelling}{18}
\bibcite{kendall2015posenet}{19}
\bibcite{gladh2016deep}{20}
\bibcite{elman1990finding}{21}
\bibcite{hochreiter1997long}{22}
\bibcite{clark2017vinet}{23}
\bibcite{patel2018contextualnet}{24}
\bibcite{wang2017deepvo}{25}
\bibcite{wang2018deepml}{26}
\bibcite{chen2018ionet}{27}
\bibcite{wang2017residual}{28}
\bibcite{luong2015effective}{29}
\bibcite{simonyan2014very}{30}
\bibcite{he2016deep}{31}
\bibcite{graves2013hybrid}{32}
\bibcite{graves2013speech}{33}
\bibcite{ullah2018action}{34}
\bibcite{schuster1997bidirectional}{35}
\bibcite{hochreiter2001gradient}{36}
\bibcite{pascanu2013difficulty}{37}
\bibcite{pascanu2012understanding}{38}
\bibcite{nair2010rectified}{39}
\bibcite{xavier2018}{40}
\bibcite{turtlebot22013}{41}
\bibcite{pozyx2018}{42}
